{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements.\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from ExperimentManager import Experiment\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as tdist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a brief description of this experiment:\n",
      "Went back to all relu, Hypers: (40, 1, agent_hyper, 1/8, 1/4, 5)\n"
     ]
    }
   ],
   "source": [
    "manager = Experiment.start_experiment('experiments2/', 'experiment', print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates network weights.\n",
    "def generate_weights(starting_size, ending_size, weights_needed):\n",
    "    difference = (starting_size - ending_size) / (weights_needed + 1)\n",
    "    weights = []\n",
    "    for i in range(weights_needed):\n",
    "        weights.append(int(starting_size - (difference * (i+1))))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy recommendor network.\n",
    "class POLICY_NET(nn.Module):\n",
    "    \n",
    "    # Constructor.\n",
    "    def __init__(self, input_size, output_size, layer_count, output_count, t_device):\n",
    "        super().__init__()\n",
    "        weights = generate_weights(input_size, output_size, layer_count)\n",
    "        prev_weight = input_size\n",
    "        self.t_device = t_device\n",
    "        self.hidden_layers = []\n",
    "        for w in weights:\n",
    "            self.hidden_layers.append(nn.Linear(prev_weight, w).to(self.t_device))\n",
    "            prev_weight = w\n",
    "        self.output_layers = []\n",
    "        for i in range(output_count):\n",
    "            self.output_layers.append(nn.Linear(prev_weight, output_size).to(self.t_device))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = F.relu\n",
    "        self.sin = torch.sin\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.params = []\n",
    "        for h in self.hidden_layers:\n",
    "            self.params += list(h.parameters())\n",
    "        for o in self.output_layers:\n",
    "            self.params += list(o.parameters())\n",
    "            \n",
    "    # Forward propogate input.\n",
    "    def forward(self, x, train=False):\n",
    "        for hidden in self.hidden_layers:\n",
    "            x = self.sin(hidden(x))\n",
    "        outputs = []\n",
    "        for out in self.output_layers:\n",
    "            if train:\n",
    "                outputs.append(self.relu(out(x)))\n",
    "            else:\n",
    "                outputs.append(self.relu(out(x)))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy rating network.\n",
    "class RATING_NET(nn.Module):\n",
    "    \n",
    "    # Constructor.\n",
    "    def __init__(self, input_size, output_size, layer_count, t_device):\n",
    "        super().__init__()\n",
    "        weights = generate_weights(input_size, output_size, layer_count)\n",
    "        prev_weight = input_size\n",
    "        self.t_device = t_device\n",
    "        self.hidden_layers = []\n",
    "        for w in weights:\n",
    "            self.hidden_layers.append(nn.Linear(prev_weight, w).to(self.t_device))\n",
    "            prev_weight = w\n",
    "        self.output_layer = nn.Linear(prev_weight, output_size).to(self.t_device)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = F.relu\n",
    "        self.sin = torch.sin\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.params = []\n",
    "        for h in self.hidden_layers:\n",
    "            self.params += list(h.parameters())\n",
    "        self.params += list(self.output_layer.parameters())\n",
    "            \n",
    "    # Forward propogate input.\n",
    "    def forward(self, x, train=False):\n",
    "        for hidden in self.hidden_layers:\n",
    "            x = self.sin(hidden(x))\n",
    "        outputs = []\n",
    "        for out in self.output_layers:\n",
    "            if train:\n",
    "                outputs.append(self.relu(out(x)))\n",
    "            else:\n",
    "                outputs.append(self.relu(out(x)))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory agent.\n",
    "class AGENT:\n",
    "    \n",
    "    # Constructor.\n",
    "    def __init__(self, name, state_size, action_size, layer_count, step_size, learning_rate, gamma, stack_size, t_device, s_device):\n",
    "        self.name = name\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.layer_count = layer_count\n",
    "        self.step_size = step_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.stack_size = stack_size\n",
    "        self.alpha = 0.1\n",
    "        self.t_device = t_device\n",
    "        self.s_device = s_device\n",
    "        self.age = 1\n",
    "        self.policy_map = POLICY_NET(state_size * stack_size, action_size, layer_count, step_size, t_device)\n",
    "        self.optimizer = torch.optim.Adam(self.policy_map.params, lr=learning_rate)\n",
    "        self.loss_func = nn.CrossEntropyLoss()#nn.MSELoss()\n",
    "    \n",
    "    # Train policy network.\n",
    "    def train_policy_network(self, inputs, outputs, extra_info='', batch_size=1024, epochs=50):\n",
    "        batches = []\n",
    "        position = 0\n",
    "        eye = torch.eye(self.action_size)\n",
    "        batch = ([],[[] for _ in range(self.step_size)])\n",
    "        losses = []\n",
    "        while position < len(inputs):\n",
    "            batch[0].append(inputs[position])\n",
    "            for i in range(len(batch[1])):\n",
    "                #batch[1][i].append(eye[outputs[i][position]])\n",
    "                batch[1][i].append(outputs[i][position])\n",
    "            position += 1\n",
    "            if len(batch[0]) >= batch_size:\n",
    "                batches.append(batch)\n",
    "                batch = ([],[[] for _ in range(self.step_size)])\n",
    "        if len(batch) > 0:\n",
    "            batches.append(batch)\n",
    "        for e in range(epochs):\n",
    "            for i in range(len(batches)):\n",
    "                inputs = torch.stack(batches[i][0])\n",
    "                #outputs = [torch.stack(o) for o in batches[i][1]]\n",
    "                outputs = [torch.Tensor(o).long() for o in batches[i][1]]\n",
    "                out = self.policy_map(inputs, train=True)\n",
    "                loss = None\n",
    "                for j in range(len(outputs)):\n",
    "                    if loss is None:\n",
    "                        loss = self.loss_func(out[j], outputs[j])\n",
    "                    else:\n",
    "                        loss += self.loss_func(out[j], outputs[j])\n",
    "                print('\\r{} | EPOCH {}/{} | BATCH {}/{} | CURRENT BATCH COUNT {} | LOSS {:0.4f} | AGE {} {}\\t\\t'.format(self.name, e+1, epochs, i+1, len(batches), len(batches[i][0]), loss.detach().cpu().numpy(), self.age, extra_info), end='')\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                losses.append(loss.detach().cpu().numpy())\n",
    "        self.age += 1\n",
    "        return sum(losses)/len(losses)\n",
    "        \n",
    "    # Plays a game.\n",
    "    def play_game(self, env, render=False, extra_info=''):\n",
    "        done = False\n",
    "        previous_state = None\n",
    "        action = 0\n",
    "        score = 0\n",
    "        inner_score = 0 # Score inside inner steps.\n",
    "        overall_step = 0\n",
    "        step = 0\n",
    "        depth = 0\n",
    "        first_step = True\n",
    "        lives = 4\n",
    "        action_queue = None\n",
    "        groups = []\n",
    "        env.reset()\n",
    "        frames = []\n",
    "        while not done:\n",
    "            if first_step:\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                state = observation\n",
    "                frames.append(state)\n",
    "                tensor = torch.Tensor.float(torch.from_numpy(state))\n",
    "                tensor = torch.cat([tensor for _ in range(self.stack_size)], 0)\n",
    "                previous_state = tensor.detach().cpu().numpy()\n",
    "                dists = self.policy_map(tensor)\n",
    "                action_queue = []\n",
    "                for d in dists:\n",
    "                    if rand.uniform(0,1) > self.gamma or min(d) < 0 or sum(d) == 0:\n",
    "                        action_queue.append(rand.randint(0, self.action_size - 1))\n",
    "                    else:\n",
    "                        distribution = torch.distributions.categorical.Categorical(d)\n",
    "                        action_queue.append(int(distribution.sample()))\n",
    "                first_step = False\n",
    "            else:\n",
    "                action = action_queue[step]\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                score += reward\n",
    "                inner_score += reward\n",
    "                state = observation\n",
    "                frames.append(state)\n",
    "                step += 1\n",
    "                if step == self.step_size:\n",
    "                    groups.append((previous_state, action_queue))\n",
    "                    step = 0\n",
    "                    inner_score = 0\n",
    "                    if len(frames) < self.stack_size:\n",
    "                        tensor = torch.Tensor.float(torch.from_numpy(state))\n",
    "                        tensor = torch.cat([tensor for _ in range(self.stack_size)], 0)\n",
    "                    else:\n",
    "                        tensors = [torch.Tensor.float(torch.from_numpy(f)) for f in frames[-self.stack_size:]]\n",
    "                        tensor = torch.cat(tensors, 0)\n",
    "                    previous_state = tensor.detach().cpu().numpy()\n",
    "                    dists = self.policy_map(tensor)\n",
    "                    action_queue = []\n",
    "                    try_rand = rand.uniform(0,1)\n",
    "                    for d in dists:\n",
    "                        if try_rand > self.gamma or sum(d) == 0:\n",
    "                            action_queue.append(rand.randint(0, self.action_size - 1))\n",
    "                        else:\n",
    "                            if min(d) < 0:\n",
    "                                d += abs(min(d))\n",
    "                            distribution = torch.distributions.categorical.Categorical(d)\n",
    "                            action_queue.append(int(distribution.sample()))\n",
    "            print('\\r{} | STEP {} | SCORE {} | AGE {} {}\\t\\t'.format(self.name, overall_step, score, self.age, extra_info), end = '')\n",
    "            if render:\n",
    "                env.render()\n",
    "            if info['ale.lives'] != lives or done:\n",
    "                lives = info['ale.lives']\n",
    "                previous_state = None\n",
    "                action = 0\n",
    "                inner_score = 0 # Score inside inner steps.\n",
    "                step = 0\n",
    "                depth = 0\n",
    "                first_step = True\n",
    "                action_queue = None\n",
    "            overall_step += 1\n",
    "        return groups, score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population of agents that learn from each other.\n",
    "class POPULATION:\n",
    "    \n",
    "    # Constructor.\n",
    "    def __init__(self, population_size, number_of_attempts, agent_params, teach_percent, train_percent, age_cutoff):\n",
    "        self.population_size = population_size\n",
    "        self.number_of_attempts = number_of_attempts\n",
    "        self.teach_percent = teach_percent\n",
    "        self.train_percent = train_percent\n",
    "        self.population = []\n",
    "        self.agents_created = population_size\n",
    "        self.age_cutoff = age_cutoff\n",
    "        self.agent_params = agent_params\n",
    "        for i in range(population_size):\n",
    "            agent = AGENT(f'AGENT_{i}', agent_params[0], agent_params[1], agent_params[2], agent_params[3], agent_params[4], agent_params[5], agent_params[6], agent_params[7], agent_params[8])\n",
    "            self.population.append(agent)\n",
    "        self.generation = 0\n",
    "        \n",
    "    # Converts a list of trajectories into valid inputs and outputs for training.\n",
    "    def convert_to_training_data(self, trajectories):\n",
    "        step_size = len(trajectories[0][1])\n",
    "        inputs = []\n",
    "        outputs = [[] for _ in range(step_size)]\n",
    "        for t in trajectories:\n",
    "            inputs.append(torch.Tensor.float(torch.from_numpy(t[0])))\n",
    "            for i in range(step_size):\n",
    "                outputs[i].append(t[1][i])\n",
    "        return inputs, outputs\n",
    "    \n",
    "    # Replaces the given agent with a new agent that is returned.\n",
    "    def replace_agent(self, agent):\n",
    "        for i in range(len(self.population)):\n",
    "            if agent.name == self.population[i].name:\n",
    "                new_agent = AGENT(f'AGENT_{self.agents_created}', self.agent_params[0], self.agent_params[1], self.agent_params[2], self.agent_params[3], self.agent_params[4], self.agent_params[5], self.agent_params[6], self.agent_params[7], self.agent_params[8])\n",
    "                self.population[i] = new_agent\n",
    "                self.agents_created += 1\n",
    "                return new_agent\n",
    "        return agent\n",
    "        \n",
    "    # Runs and trains the agents.\n",
    "    def run_population(self, env, render=False):\n",
    "        new_pop = []\n",
    "        total_score = 0\n",
    "        high_score = None\n",
    "        low_score = None\n",
    "        manager.print('BEGIN RUNNING POPULATION | GENERATION {}'.format(self.generation))\n",
    "        rand.shuffle(self.population)\n",
    "        for agent in self.population:\n",
    "            candidate_runs = []\n",
    "            for g in range(self.number_of_attempts):\n",
    "                groups, score = agent.play_game(env, render, f'| MEMBER {len(new_pop) + 1}/{len(self.population)} | GAME {g+1}/{self.number_of_attempts}')\n",
    "                total_score += score\n",
    "                candidate_runs.append((groups, score))\n",
    "                if high_score is None or high_score < score:\n",
    "                    high_score = score\n",
    "                if low_score is None or low_score > score:\n",
    "                    low_score = score\n",
    "            candidate_runs.sort(key = lambda x: x[1], reverse=True)\n",
    "            new_pop.append((agent, candidate_runs[0][0], candidate_runs[0][1]))\n",
    "            \n",
    "            #all_groups = []\n",
    "            #agent_score = 0\n",
    "            #for g in range(self.number_of_attempts):\n",
    "            #    groups, score = agent.play_game(env, render, f'| MEMBER {len(new_pop) + 1}/{len(self.population)} | GAME {g+1}/{self.number_of_attempts}')\n",
    "            #    all_groups += groups\n",
    "            #    agent_score += score\n",
    "            #    total_score += score\n",
    "            #    if high_score is None or high_score < score:\n",
    "            #        high_score = score\n",
    "            #    if low_score is None or low_score > score:\n",
    "            #        low_score = score\n",
    "            #new_pop.append((agent, all_groups, agent_score / self.number_of_attempts))\n",
    "        print('\\n')\n",
    "        manager.print('END RUNNING POPULATION | AVERAGE SCORE {} | LOW SCORE {} | HIGH SCORE {}'.format(total_score / (len(new_pop) * self.number_of_attempts), low_score, high_score))\n",
    "        new_pop.sort(key = lambda x: x[2], reverse=True)\n",
    "        teach_pop = new_pop[:int(len(new_pop) * self.teach_percent)]\n",
    "        train_pop = new_pop[-int(len(new_pop) * self.train_percent):]\n",
    "        examples = []\n",
    "        for exp in teach_pop:\n",
    "            examples += exp[1]\n",
    "        manager.print('BEGIN TRAINING POPULATION')\n",
    "        count = 0\n",
    "        losses = []\n",
    "        for train in train_pop:\n",
    "            agent = train[0]\n",
    "            if agent.age > self.age_cutoff and rand.uniform(0,1) > 0.5:\n",
    "                agent = self.replace_agent(agent)\n",
    "            trajectories = []\n",
    "            for _ in range(int(len(examples) / 2)):\n",
    "                index = rand.randint(0, len(examples) - 1)\n",
    "                trajectories.append(examples[index])\n",
    "            inputs, outputs = self.convert_to_training_data(trajectories)\n",
    "            loss = agent.train_policy_network(inputs, outputs, extra_info=f'| MEMBER {count+1}/{len(train_pop)}', batch_size=1024, epochs=50)\n",
    "            losses.append(loss)\n",
    "            count += 1\n",
    "        print('\\n')\n",
    "        manager.print('END TRAINING POPULATION | AVG LOSS {}'.format(sum(losses)/len(losses)))\n",
    "        self.generation += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_hyper = (128, 14, 10, 2, 0.001, 0.95, 5, torch.device('cpu'), torch.device('cpu'))\n",
    "population = POPULATION(40, 1, agent_hyper, 1/8, 1/4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('KungFuMaster-ram-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN RUNNING POPULATION | GENERATION 0\n",
      "AGENT_19 | STEP 1783 | SCORE 2100.0 | AGE 1 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 872.5 | LOW SCORE 0.0 | HIGH SCORE 5000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_27 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 403 | LOSS 5.2057 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.1997364384333284\n",
      "BEGIN RUNNING POPULATION | GENERATION 1\n",
      "AGENT_4 | STEP 1411 | SCORE 1200.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 1150.0 | LOW SCORE 0.0 | HIGH SCORE 3800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_2 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 738 | LOSS 5.1905 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.127672968228658\n",
      "BEGIN RUNNING POPULATION | GENERATION 2\n",
      "AGENT_1 | STEP 1424 | SCORE 1200.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 1352.5 | LOW SCORE 0.0 | HIGH SCORE 3600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_23 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 391 | LOSS 5.1658 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.132044654846192\n",
      "BEGIN RUNNING POPULATION | GENERATION 3\n",
      "AGENT_4 | STEP 1500 | SCORE 900.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 1420.0 | LOW SCORE 300.0 | HIGH SCORE 4800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_9 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 442 | LOSS 5.0133 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.039992985407511\n",
      "BEGIN RUNNING POPULATION | GENERATION 4\n",
      "AGENT_20 | STEP 1462 | SCORE 500.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 1645.0 | LOW SCORE 400.0 | HIGH SCORE 3900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_33 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 475 | LOSS 4.9037 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.051181041717529\n",
      "BEGIN RUNNING POPULATION | GENERATION 5\n",
      "AGENT_0 | STEP 951 | SCORE 0.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 1920.0 | LOW SCORE 0.0 | HIGH SCORE 4800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_0 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 526 | LOSS 4.9257 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.033227467854818\n",
      "BEGIN RUNNING POPULATION | GENERATION 6\n",
      "AGENT_33 | STEP 1191 | SCORE 900.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 2127.5 | LOW SCORE 300.0 | HIGH SCORE 5200.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_4 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 657 | LOSS 5.0083 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 5.076678657849629\n",
      "BEGIN RUNNING POPULATION | GENERATION 7\n",
      "AGENT_19 | STEP 1904 | SCORE 2300.0 | AGE 1 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 2365.0 | LOW SCORE 700.0 | HIGH SCORE 6800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_22 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 113 | LOSS 4.8958 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.97574107480049\n",
      "BEGIN RUNNING POPULATION | GENERATION 8\n",
      "AGENT_35 | STEP 1417 | SCORE 1100.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 2527.5 | LOW SCORE 600.0 | HIGH SCORE 5000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_20 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 80 | LOSS 5.0267 | AGE 4 | MEMBER 10/10\t\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.9683008537292475\n",
      "BEGIN RUNNING POPULATION | GENERATION 9\n",
      "AGENT_34 | STEP 1613 | SCORE 2300.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 2725.0 | LOW SCORE 700.0 | HIGH SCORE 6400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_26 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 674 | LOSS 4.5322 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.758185270309449\n",
      "BEGIN RUNNING POPULATION | GENERATION 10\n",
      "AGENT_18 | STEP 2166 | SCORE 4500.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3305.0 | LOW SCORE 1400.0 | HIGH SCORE 6600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_27 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 553 | LOSS 4.5051 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.5711207857131955\n",
      "BEGIN RUNNING POPULATION | GENERATION 11\n",
      "AGENT_26 | STEP 2229 | SCORE 3200.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3447.5 | LOW SCORE 800.0 | HIGH SCORE 8700.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_29 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 294 | LOSS 4.4357 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.577121061563492\n",
      "BEGIN RUNNING POPULATION | GENERATION 12\n",
      "AGENT_16 | STEP 1436 | SCORE 1600.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3195.0 | LOW SCORE 1400.0 | HIGH SCORE 6400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_36 | EPOCH 50/50 | BATCH 3/3 | CURRENT BATCH COUNT 859 | LOSS 4.8489 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.494537680625916\n",
      "BEGIN RUNNING POPULATION | GENERATION 13\n",
      "AGENT_19 | STEP 1826 | SCORE 3700.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3642.5 | LOW SCORE 500.0 | HIGH SCORE 7100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_9 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 297 | LOSS 4.4236 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.524256580829621\n",
      "BEGIN RUNNING POPULATION | GENERATION 14\n",
      "AGENT_1 | STEP 2499 | SCORE 5300.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3707.5 | LOW SCORE 800.0 | HIGH SCORE 12400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_19 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 839 | LOSS 4.2352 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.47474614906311\n",
      "BEGIN RUNNING POPULATION | GENERATION 15\n",
      "AGENT_35 | STEP 2529 | SCORE 4400.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3795.0 | LOW SCORE 600.0 | HIGH SCORE 9000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_22 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 304 | LOSS 4.6320 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.436403901100158\n",
      "BEGIN RUNNING POPULATION | GENERATION 16\n",
      "AGENT_13 | STEP 2259 | SCORE 5300.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3695.0 | LOW SCORE 1100.0 | HIGH SCORE 7400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_44 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 301 | LOSS 4.5524 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.569631324768067\n",
      "BEGIN RUNNING POPULATION | GENERATION 17\n",
      "AGENT_41 | STEP 1633 | SCORE 2000.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3942.5 | LOW SCORE 500.0 | HIGH SCORE 8800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_42 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 445 | LOSS 4.5563 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.568170884370804\n",
      "BEGIN RUNNING POPULATION | GENERATION 18\n",
      "AGENT_13 | STEP 2038 | SCORE 3200.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4032.5 | LOW SCORE 900.0 | HIGH SCORE 8100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_41 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 411 | LOSS 4.1544 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.325507762670517\n",
      "BEGIN RUNNING POPULATION | GENERATION 19\n",
      "AGENT_1 | STEP 2407 | SCORE 5000.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3447.5 | LOW SCORE 700.0 | HIGH SCORE 8500.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_41 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 273 | LOSS 4.7217 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.662570331096649\n",
      "BEGIN RUNNING POPULATION | GENERATION 20\n",
      "AGENT_41 | STEP 1521 | SCORE 1700.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3620.0 | LOW SCORE 500.0 | HIGH SCORE 8900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_43 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 436 | LOSS 4.4232 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.501072043418885\n",
      "BEGIN RUNNING POPULATION | GENERATION 21\n",
      "AGENT_32 | STEP 2142 | SCORE 2000.0 | AGE 8 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3817.5 | LOW SCORE 600.0 | HIGH SCORE 6900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_50 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 498 | LOSS 4.4816 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.6613156867027286\n",
      "BEGIN RUNNING POPULATION | GENERATION 22\n",
      "AGENT_8 | STEP 2618 | SCORE 4400.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3435.0 | LOW SCORE 1000.0 | HIGH SCORE 6600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_52 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 270 | LOSS 4.2413 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.4904714028835295\n",
      "BEGIN RUNNING POPULATION | GENERATION 23\n",
      "AGENT_11 | STEP 2446 | SCORE 4100.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3652.5 | LOW SCORE 800.0 | HIGH SCORE 8100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_55 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 390 | LOSS 4.4852 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.465673621416092\n",
      "BEGIN RUNNING POPULATION | GENERATION 24\n",
      "AGENT_30 | STEP 3003 | SCORE 6900.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3705.0 | LOW SCORE 500.0 | HIGH SCORE 8000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_50 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 467 | LOSS 4.4021 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.522559017181396\n",
      "BEGIN RUNNING POPULATION | GENERATION 25\n",
      "AGENT_59 | STEP 1241 | SCORE 700.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3582.5 | LOW SCORE 400.0 | HIGH SCORE 7800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_56 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 269 | LOSS 4.2150 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.384291209936142\n",
      "BEGIN RUNNING POPULATION | GENERATION 26\n",
      "AGENT_50 | STEP 3096 | SCORE 2600.0 | AGE 8 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3672.5 | LOW SCORE 800.0 | HIGH SCORE 6600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_48 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 350 | LOSS 4.5738 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.531887017488481\n",
      "BEGIN RUNNING POPULATION | GENERATION 27\n",
      "AGENT_47 | STEP 1598 | SCORE 2100.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3815.0 | LOW SCORE 600.0 | HIGH SCORE 6400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_52 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 184 | LOSS 4.3548 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.580955404996873\n",
      "BEGIN RUNNING POPULATION | GENERATION 28\n",
      "AGENT_54 | STEP 2756 | SCORE 4000.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3787.5 | LOW SCORE 800.0 | HIGH SCORE 8100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_63 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 358 | LOSS 4.0543 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.336402962684631\n",
      "BEGIN RUNNING POPULATION | GENERATION 29\n",
      "AGENT_29 | STEP 2280 | SCORE 5700.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3557.5 | LOW SCORE 1000.0 | HIGH SCORE 6400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_48 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 393 | LOSS 4.5041 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.406663348197936\n",
      "BEGIN RUNNING POPULATION | GENERATION 30\n",
      "AGENT_48 | STEP 1756 | SCORE 2900.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3637.5 | LOW SCORE 0.0 | HIGH SCORE 7900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_56 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 238 | LOSS 4.6240 | AGE 8 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.490698323011399\n",
      "BEGIN RUNNING POPULATION | GENERATION 31\n",
      "AGENT_5 | STEP 2138 | SCORE 2900.0 | AGE 9 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3325.0 | LOW SCORE 400.0 | HIGH SCORE 6200.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_62 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 343 | LOSS 4.2788 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.301775540232659\n",
      "BEGIN RUNNING POPULATION | GENERATION 32\n",
      "AGENT_39 | STEP 2413 | SCORE 4600.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3842.5 | LOW SCORE 1000.0 | HIGH SCORE 8600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_56 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 747 | LOSS 4.5482 | AGE 10 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.452512796878815\n",
      "BEGIN RUNNING POPULATION | GENERATION 33\n",
      "AGENT_51 | STEP 2401 | SCORE 4500.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3925.0 | LOW SCORE 1400.0 | HIGH SCORE 10700.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_70 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 853 | LOSS 4.7350 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.520457205533981\n",
      "BEGIN RUNNING POPULATION | GENERATION 34\n",
      "AGENT_68 | STEP 995 | SCORE 0.0 | AGE 2 | MEMBER 40/40 | GAME 1/1\t\t1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3660.0 | LOW SCORE 0.0 | HIGH SCORE 8800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_68 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 608 | LOSS 4.3888 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.648723282337189\n",
      "BEGIN RUNNING POPULATION | GENERATION 35\n",
      "AGENT_8 | STEP 2383 | SCORE 4600.0 | AGE 8 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3677.5 | LOW SCORE 500.0 | HIGH SCORE 7400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_73 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 363 | LOSS 4.2958 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.431206652641297\n",
      "BEGIN RUNNING POPULATION | GENERATION 36\n",
      "AGENT_24 | STEP 1878 | SCORE 2800.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3822.5 | LOW SCORE 900.0 | HIGH SCORE 7300.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_63 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 138 | LOSS 4.4933 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.437979248523712\n",
      "BEGIN RUNNING POPULATION | GENERATION 37\n",
      "AGENT_58 | STEP 1666 | SCORE 1600.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3787.5 | LOW SCORE 500.0 | HIGH SCORE 9000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_63 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 856 | LOSS 4.3132 | AGE 7 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.49737769460678\n",
      "BEGIN RUNNING POPULATION | GENERATION 38\n",
      "AGENT_54 | STEP 2019 | SCORE 1900.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3482.5 | LOW SCORE 600.0 | HIGH SCORE 7500.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_73 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 132 | LOSS 4.5785 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.447810943603516\n",
      "BEGIN RUNNING POPULATION | GENERATION 39\n",
      "AGENT_35 | STEP 2042 | SCORE 2700.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3912.5 | LOW SCORE 1200.0 | HIGH SCORE 7400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_25 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 564 | LOSS 4.3727 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.5728665127754216\n",
      "BEGIN RUNNING POPULATION | GENERATION 40\n",
      "AGENT_65 | STEP 1888 | SCORE 2100.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3697.5 | LOW SCORE 500.0 | HIGH SCORE 9000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_79 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 675 | LOSS 4.2093 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.538167341470719\n",
      "BEGIN RUNNING POPULATION | GENERATION 41\n",
      "AGENT_39 | STEP 1850 | SCORE 4100.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3835.0 | LOW SCORE 800.0 | HIGH SCORE 10000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_82 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 966 | LOSS 4.0724 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.438867221355438\n",
      "BEGIN RUNNING POPULATION | GENERATION 42\n",
      "AGENT_18 | STEP 1983 | SCORE 3300.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3670.0 | LOW SCORE 700.0 | HIGH SCORE 8000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_79 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 119 | LOSS 4.1791 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.388377238273621\n",
      "BEGIN RUNNING POPULATION | GENERATION 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT_1 | STEP 2362 | SCORE 4400.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3765.0 | LOW SCORE 800.0 | HIGH SCORE 9100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_83 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 563 | LOSS 3.9835 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.420437060236931\n",
      "BEGIN RUNNING POPULATION | GENERATION 44\n",
      "AGENT_67 | STEP 2908 | SCORE 6300.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3705.0 | LOW SCORE 1200.0 | HIGH SCORE 6900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_83 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 297 | LOSS 4.1297 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.186454089641571\n",
      "BEGIN RUNNING POPULATION | GENERATION 45\n",
      "AGENT_81 | STEP 2787 | SCORE 5700.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3910.0 | LOW SCORE 600.0 | HIGH SCORE 6900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_92 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 424 | LOSS 4.4819 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.467024897336961\n",
      "BEGIN RUNNING POPULATION | GENERATION 46\n",
      "AGENT_88 | STEP 2163 | SCORE 3100.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3932.5 | LOW SCORE 1400.0 | HIGH SCORE 9900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_25 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 911 | LOSS 4.2750 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.304965739846229\n",
      "BEGIN RUNNING POPULATION | GENERATION 47\n",
      "AGENT_92 | STEP 1513 | SCORE 1500.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4490.0 | LOW SCORE 1500.0 | HIGH SCORE 10000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_92 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 933 | LOSS 4.1979 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.331200574874878\n",
      "BEGIN RUNNING POPULATION | GENERATION 48\n",
      "AGENT_45 | STEP 1930 | SCORE 3100.0 | AGE 10 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3975.0 | LOW SCORE 900.0 | HIGH SCORE 8400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_92 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 700 | LOSS 4.2099 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.263517573595047\n",
      "BEGIN RUNNING POPULATION | GENERATION 49\n",
      "AGENT_71 | STEP 2365 | SCORE 4400.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3687.5 | LOW SCORE 1100.0 | HIGH SCORE 8300.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_89 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 565 | LOSS 4.4167 | AGE 6 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.325674303770065\n",
      "BEGIN RUNNING POPULATION | GENERATION 50\n",
      "AGENT_54 | STEP 2237 | SCORE 3400.0 | AGE 8 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4095.0 | LOW SCORE 900.0 | HIGH SCORE 9600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_97 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 1014 | LOSS 4.6015 | AGE 1 | MEMBER 10/10\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.291355547785758\n",
      "BEGIN RUNNING POPULATION | GENERATION 51\n",
      "AGENT_10 | STEP 2255 | SCORE 5300.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3862.5 | LOW SCORE 1100.0 | HIGH SCORE 8800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_70 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 773 | LOSS 4.2208 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.373337795495988\n",
      "BEGIN RUNNING POPULATION | GENERATION 52\n",
      "AGENT_84 | STEP 2957 | SCORE 5000.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3930.0 | LOW SCORE 1200.0 | HIGH SCORE 7800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_93 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 562 | LOSS 4.1839 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.47691264462471\n",
      "BEGIN RUNNING POPULATION | GENERATION 53\n",
      "AGENT_53 | STEP 1680 | SCORE 2700.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3635.0 | LOW SCORE 800.0 | HIGH SCORE 7600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_93 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 766 | LOSS 4.2879 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.3623480701446535\n",
      "BEGIN RUNNING POPULATION | GENERATION 54\n",
      "AGENT_81 | STEP 1482 | SCORE 1900.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3587.5 | LOW SCORE 1400.0 | HIGH SCORE 6500.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_104 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 116 | LOSS 4.5549 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.444163810014724\n",
      "BEGIN RUNNING POPULATION | GENERATION 55\n",
      "AGENT_6 | STEP 2268 | SCORE 4700.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3970.0 | LOW SCORE 700.0 | HIGH SCORE 8800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_104 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 988 | LOSS 4.0491 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.47490366601944\n",
      "BEGIN RUNNING POPULATION | GENERATION 56\n",
      "AGENT_10 | STEP 2612 | SCORE 6000.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3735.0 | LOW SCORE 700.0 | HIGH SCORE 8600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_106 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 862 | LOSS 4.1919 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.443308390140533\n",
      "BEGIN RUNNING POPULATION | GENERATION 57\n",
      "AGENT_1 | STEP 2613 | SCORE 3500.0 | AGE 7 | MEMBER 40/40 | GAME 1/1\t\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4105.0 | LOW SCORE 500.0 | HIGH SCORE 9000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_104 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 972 | LOSS 4.1272 | AGE 4 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.313235563993454\n",
      "BEGIN RUNNING POPULATION | GENERATION 58\n",
      "AGENT_97 | STEP 2293 | SCORE 4600.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3765.0 | LOW SCORE 300.0 | HIGH SCORE 9100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_104 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 542 | LOSS 4.0818 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.3197470879554745\n",
      "BEGIN RUNNING POPULATION | GENERATION 59\n",
      "AGENT_67 | STEP 2064 | SCORE 3100.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3755.0 | LOW SCORE 1000.0 | HIGH SCORE 6800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_108 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 444 | LOSS 4.1481 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.255895226716996\n",
      "BEGIN RUNNING POPULATION | GENERATION 60\n",
      "AGENT_87 | STEP 4526 | SCORE 8000.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3497.5 | LOW SCORE 1000.0 | HIGH SCORE 8000.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_116 | EPOCH 50/50 | BATCH 5/5 | CURRENT BATCH COUNT 53 | LOSS 4.4945 | AGE 1 | MEMBER 10/10\t\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.557736824989319\n",
      "BEGIN RUNNING POPULATION | GENERATION 61\n",
      "AGENT_29 | STEP 2400 | SCORE 5000.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3575.0 | LOW SCORE 700.0 | HIGH SCORE 7200.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_118 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 511 | LOSS 4.5255 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.563294760704041\n",
      "BEGIN RUNNING POPULATION | GENERATION 62\n",
      "AGENT_103 | STEP 2783 | SCORE 6600.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4010.0 | LOW SCORE 2000.0 | HIGH SCORE 6800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_118 | EPOCH 50/50 | BATCH 5/5 | CURRENT BATCH COUNT 277 | LOSS 4.5680 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.618732368087768\n",
      "BEGIN RUNNING POPULATION | GENERATION 63\n",
      "AGENT_87 | STEP 3157 | SCORE 6100.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4357.5 | LOW SCORE 1600.0 | HIGH SCORE 8500.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_114 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 982 | LOSS 4.2120 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.458063850879669\n",
      "BEGIN RUNNING POPULATION | GENERATION 64\n",
      "AGENT_84 | STEP 1694 | SCORE 2600.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3920.0 | LOW SCORE 800.0 | HIGH SCORE 7100.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_119 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 177 | LOSS 4.0313 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.257034321784973\n",
      "BEGIN RUNNING POPULATION | GENERATION 65\n",
      "AGENT_81 | STEP 2617 | SCORE 3100.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3975.0 | LOW SCORE 400.0 | HIGH SCORE 7400.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_94 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 856 | LOSS 4.6369 | AGE 7 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.601765530347825\n",
      "BEGIN RUNNING POPULATION | GENERATION 66\n",
      "AGENT_113 | STEP 2138 | SCORE 2200.0 | AGE 4 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3532.5 | LOW SCORE 800.0 | HIGH SCORE 7700.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_121 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 723 | LOSS 4.1700 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.521429461240769\n",
      "BEGIN RUNNING POPULATION | GENERATION 67\n",
      "AGENT_87 | STEP 1537 | SCORE 1700.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3972.5 | LOW SCORE 900.0 | HIGH SCORE 9800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_126 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 883 | LOSS 3.9340 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.311199450135231\n",
      "BEGIN RUNNING POPULATION | GENERATION 68\n",
      "AGENT_118 | STEP 2197 | SCORE 2600.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3672.5 | LOW SCORE 500.0 | HIGH SCORE 7800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_124 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 814 | LOSS 4.1471 | AGE 3 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.389915139913558\n",
      "BEGIN RUNNING POPULATION | GENERATION 69\n",
      "AGENT_97 | STEP 2272 | SCORE 5800.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4015.0 | LOW SCORE 500.0 | HIGH SCORE 7800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_122 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 409 | LOSS 4.0967 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.259125985145569\n",
      "BEGIN RUNNING POPULATION | GENERATION 70\n",
      "AGENT_77 | STEP 3133 | SCORE 7000.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 4070.0 | LOW SCORE 800.0 | HIGH SCORE 9600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_124 | EPOCH 50/50 | BATCH 5/5 | CURRENT BATCH COUNT 174 | LOSS 4.0677 | AGE 5 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.4003745580673215\n",
      "BEGIN RUNNING POPULATION | GENERATION 71\n",
      "AGENT_10 | STEP 2488 | SCORE 5600.0 | AGE 6 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3700.0 | LOW SCORE 600.0 | HIGH SCORE 9800.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_135 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 503 | LOSS 4.7024 | AGE 1 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.415919693231583\n",
      "BEGIN RUNNING POPULATION | GENERATION 72\n",
      "AGENT_70 | STEP 2452 | SCORE 5000.0 | AGE 5 | MEMBER 40/40 | GAME 1/1\t\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3622.5 | LOW SCORE 300.0 | HIGH SCORE 8900.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_134 | EPOCH 50/50 | BATCH 4/4 | CURRENT BATCH COUNT 740 | LOSS 4.3144 | AGE 2 | MEMBER 10/10\t\t\t\n",
      "\n",
      "END TRAINING POPULATION | AVG LOSS 4.313082695245742\n",
      "BEGIN RUNNING POPULATION | GENERATION 73\n",
      "AGENT_120 | STEP 2568 | SCORE 6600.0 | AGE 3 | MEMBER 40/40 | GAME 1/1\t\t\n",
      "\n",
      "END RUNNING POPULATION | AVERAGE SCORE 3982.5 | LOW SCORE 800.0 | HIGH SCORE 8600.0\n",
      "BEGIN TRAINING POPULATION\n",
      "AGENT_117 | EPOCH 39/50 | BATCH 1/4 | CURRENT BATCH COUNT 1024 | LOSS 4.3051 | AGE 3 | MEMBER 4/10\t\t"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    population.run_population(env, True)\n",
    "    manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
